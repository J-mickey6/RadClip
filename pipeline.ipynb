{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a69f8db",
   "metadata": {},
   "source": [
    "### Text & Image 매핑 -> tokenzier & embedding\n",
    "- tokenzier : 이미지의 경우 patch로 나눠서 각 숫자 벡터로 바꿈\n",
    "              자연어의 경우 단어 하나하나를 임베딩해서 문장을 토큰 시퀀스로 만드는 것\n",
    "              = Input Slice encoding\n",
    "              + Learned positional encoding(슬라이스 순서)\n",
    "- embedding : 위 token한 값을 각 이미지나 단어에 매핑됨\n",
    "\n",
    "- Transformer : token + embedding 후 2단계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea5081bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\visual code\\MRI\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import CLIPModel, CLIPTokenizer, CLIPProcessor\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5cfaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Load CLIP model & processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device).eval()\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5daef3",
   "metadata": {},
   "source": [
    "### 이미 PD, PDX 분류한 폴더에 접근해서 2D 데이터 + text + label 해서 입력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e3f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 텍스트 프롬프트 정의\n",
    "text_prompts = {\n",
    "    \"PD\": [\n",
    "        \"Brain MRI with Parkinson's disease\",\n",
    "        \"T1-weighted axial brain MRI showing Parkinsonian features\",\n",
    "        \"MRI scan of the brain affected by Parkinson's disease\",\n",
    "        \"Neuroimaging of a patient diagnosed with Parkinson's\",\n",
    "        \"Axial brain MRI with signs of neurodegeneration\"\n",
    "    ],\n",
    "    \"PDX\": [\n",
    "        \"Brain MRI of a healthy subject\",\n",
    "        \"T1-weighted axial brain MRI without abnormalities\",\n",
    "        \"Normal brain scan with no pathological findings\",\n",
    "        \"Control subject brain MRI image\",\n",
    "        \"Axial brain MRI with typical anatomy and no disease\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "label_map = {\"PD\": 0, \"PDX\": 1}\n",
    "\n",
    "# 2. 이미지-텍스트 쌍 수집 함수\n",
    "def collect_image_text_pairs(root_dir):\n",
    "    imagetext_dataset = []\n",
    "\n",
    "    label_dirs = {\n",
    "        \"PD\": 0,\n",
    "        \"PDX\": 1\n",
    "    }\n",
    "\n",
    "    for label_key, label_value in label_dirs.items():\n",
    "        subject_root = os.path.join(root_dir, label_key)\n",
    "        subject_folders = glob.glob(os.path.join(subject_root, \"RJPD_*\"))\n",
    "\n",
    "        for subject_folder in subject_folders:\n",
    "            image_dir = os.path.join(subject_folder, f\"T1_{label_key}\")\n",
    "            image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.png\")))\n",
    "\n",
    "            if len(image_paths) != 70:\n",
    "                print(f\"⚠️ {label_key} - {os.path.basename(subject_folder)}: 슬라이스 수 = {len(image_paths)} (70장 아님)\")\n",
    "\n",
    "            for img_path in image_paths:\n",
    "                text_prompt = random.choice(text_prompts[label_key])  # 라벨에 맞는 텍스트\n",
    "                imagetext_dataset.append((img_path, text_prompt))\n",
    "\n",
    "    print(f\"✅ 총 수집된 이미지-텍스트 쌍: {len(imagetext_dataset)}\")\n",
    "    return imagetext_dataset\n",
    "\n",
    "# 3. CLIPDataset 정의\n",
    "class CLIPDataset(Dataset):\n",
    "    def __init__(self, imagetext_dataset):\n",
    "        self.imagetext_dataset = imagetext_dataset  # 리스트: (img_path, text, label)\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", use_fast=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagetext_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, text, label = self.imagetext_dataset[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        processed = self.processor(text=text, images=image, return_tensors=\"pt\", padding=\"max_length\")\n",
    "\n",
    "        # 배치 차원 제거\n",
    "        processed = {k: v.squeeze(0) for k, v in processed.items()}\n",
    "        processed[\"label\"] = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48d9769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 수집된 이미지-텍스트 쌍: 14000\n",
      "{'input_ids': tensor([49406,  4812, 24773,   593, 28129,   568,  5336, 49407, 49407, 49407,\n",
      "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
      "        49407, 49407, 49407, 49407, 49407, 49407, 49407]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0]), 'pixel_values': tensor([[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
      "         [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
      "         [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
      "         ...,\n",
      "         [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
      "         [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
      "         [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923]],\n",
      "\n",
      "        [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
      "         [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
      "         [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
      "         ...,\n",
      "         [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
      "         [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
      "         [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521]],\n",
      "\n",
      "        [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
      "         [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
      "         [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
      "         ...,\n",
      "         [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
      "         [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
      "         [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802]]]), 'label': tensor(0)}\n"
     ]
    }
   ],
   "source": [
    "root_dir = r\"C:\\visual code\\MRI\\dataset\\MRI_train\"\n",
    "imagetext_dataset = collect_image_text_pairs(root_dir)\n",
    "\n",
    "dataset = CLIPDataset(imagetext_dataset)\n",
    "print(dataset[0])  # 하나만 예시로 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f3dce",
   "metadata": {},
   "source": [
    "### AttentionPoolingAdapter\n",
    "- multi-head attention 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7683018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AttentionPoolingAdapter(nn.Module):\n",
    "    def __init__(self, embed_dim=1024, num_heads=8, num_slices=70):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_slices = num_slices\n",
    "\n",
    "        # Learnable positional encoding: (num_slices, embed_dim)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(num_slices, embed_dim))\n",
    "\n",
    "        # Multi-head self-attention\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, cls_sequence):\n",
    "        \"\"\"\n",
    "        cls_sequence: Tensor of shape (70, 1024) ← 70 slices의 CLS 벡터\n",
    "        Returns: pooled_output (1, 1024)\n",
    "        \"\"\"\n",
    "        if cls_sequence.dim() == 2:\n",
    "            cls_sequence = cls_sequence.unsqueeze(0)  # (1, 70, 1024)\n",
    "\n",
    "        # Positional encoding 추가\n",
    "        cls_sequence = cls_sequence + self.positional_encoding.unsqueeze(0)  # (1, 70, 1024)\n",
    "\n",
    "        # Self-attention\n",
    "        attn_output, _ = self.attn(cls_sequence, cls_sequence, cls_sequence, need_weights=False)  # (1, 70, 1024)\n",
    "\n",
    "        # Mean pooling across slices\n",
    "        pooled = attn_output.mean(dim=1)  # (1, 1024)\n",
    "        pooled = self.norm(pooled)\n",
    "\n",
    "        return pooled  # shape: (1, 1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21cb4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Final pooled embedding: tensor([[1.0010, 0.3381, 0.3126,  ..., 1.3538, 0.2206, 1.5222]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "📐 Shape: torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "adapter = AttentionPoolingAdapter(embed_dim=1024, num_heads=8, num_slices=70)\n",
    "\n",
    "# 예시 입력 (70개의 CLS 임베딩)\n",
    "cls_sequence = torch.randn(70, 1024)  # (num_slices, embed_dim)\n",
    "\n",
    "# forward 실행\n",
    "pooled = adapter(cls_sequence)\n",
    "\n",
    "# 출력\n",
    "print(\"🟢 Final pooled embedding:\", pooled)\n",
    "print(\"📐 Shape:\", pooled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647b819a",
   "metadata": {},
   "source": [
    "### Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e36ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss(image_embeddings, text_embeddings, temperature=0.07):\n",
    "\n",
    "    # 1. Normalize embeddings\n",
    "    image_embeddings = F.normalize(image_embeddings, dim=-1)  # (B, D)\n",
    "    text_embeddings = F.normalize(text_embeddings, dim=-1)    # (B, D)\n",
    "\n",
    "    # Cosine similarity as logits\n",
    "    logits_per_image = torch.matmul(image_embeddings, text_embeddings.T) / temperature\n",
    "\n",
    "    logits_per_text = logits_per_image.T  # transpose for text-to-image\n",
    "\n",
    "    # 3. Ground truth labels: diagonal (i == j)\n",
    "    batch_size = image_embeddings.size(0)\n",
    "    labels = torch.arange(batch_size, device=image_embeddings.device)\n",
    "\n",
    "    # 4. Cross-entropy loss (image → text + text → image)\n",
    "    loss_i2t = F.cross_entropy(logits_per_image, labels)\n",
    "    loss_t2i = F.cross_entropy(logits_per_text, labels)\n",
    "    loss = (loss_i2t + loss_t2i) / 2\n",
    "\n",
    "    return loss, logits_per_image, logits_per_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973323e",
   "metadata": {},
   "source": [
    "### CLIP Model에서 image 부분 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da60aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.clip.modeling_clip import CLIPModel, CLIPTextModel, CLIPVisionModel, CLIPOutput, _get_vector_norm\n",
    "from transformers.models.clip.configuration_clip import CLIPConfig, CLIPTextConfig, CLIPVisionConfig\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPooling\n",
    "from transformers.utils import can_return_tuple\n",
    "from transformers import CLIPPreTrainedModel\n",
    "from typing import Optional\n",
    "\n",
    "class CLIPModel(CLIPPreTrainedModel):\n",
    "    config: CLIPConfig\n",
    "    _no_split_modules = [\"CLIPTextEmbeddings\", \"CLIPEncoderLayer\", \"CLIPVisionEmbeddings\"]\n",
    "\n",
    "    def __init__(self, config: CLIPConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if not isinstance(config.text_config, CLIPTextConfig):\n",
    "            raise TypeError(\n",
    "                \"config.text_config is expected to be of type CLIPTextConfig but is of type\"\n",
    "                f\" {type(config.text_config)}.\"\n",
    "            )\n",
    "\n",
    "        if not isinstance(config.vision_config, CLIPVisionConfig):\n",
    "            raise TypeError(\n",
    "                \"config.vision_config is expected to be of type CLIPVisionConfig but is of type\"\n",
    "                f\" {type(config.vision_config)}.\"\n",
    "            )\n",
    "\n",
    "        text_config = config.text_config\n",
    "        vision_config = config.vision_config\n",
    "\n",
    "        self.projection_dim = config.projection_dim\n",
    "        self.text_embed_dim = text_config.hidden_size\n",
    "        self.vision_embed_dim = vision_config.hidden_size\n",
    "\n",
    "        text_model = CLIPTextModel._from_config(text_config)\n",
    "        self.text_model = text_model.text_model\n",
    "\n",
    "        vision_model = CLIPVisionModel._from_config(vision_config)\n",
    "        self.vision_model = vision_model.vision_model\n",
    "\n",
    "        self.visual_projection = nn.Linear(self.vision_embed_dim, self.projection_dim, bias=False)\n",
    "        self.text_projection = nn.Linear(self.text_embed_dim, self.projection_dim, bias=False)\n",
    "        self.logit_scale = nn.Parameter(torch.tensor(self.config.logit_scale_init_value))\n",
    "\n",
    "        self.post_init()\n",
    "\n",
    "    def get_text_features(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        text_outputs: BaseModelOutputWithPooling = self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "\n",
    "        pooled_output = text_outputs.pooler_output\n",
    "        text_features = self.text_projection(pooled_output)\n",
    "\n",
    "        return text_features\n",
    "\n",
    "    def get_image_features(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        interpolate_pos_encoding: bool = False,\n",
    "    ) -> torch.FloatTensor:\n",
    "\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        vision_outputs: BaseModelOutputWithPooling = self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            interpolate_pos_encoding=interpolate_pos_encoding,\n",
    "        )\n",
    "\n",
    "        pooled_output = vision_outputs.pooler_output\n",
    "        image_features = self.visual_projection(pooled_output)\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    @can_return_tuple\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        return_loss: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        interpolate_pos_encoding: bool = False,\n",
    "    ) -> CLIPOutput:\n",
    "\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        vision_outputs: BaseModelOutputWithPooling = self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            interpolate_pos_encoding=interpolate_pos_encoding,\n",
    "        )\n",
    "\n",
    "        text_outputs: BaseModelOutputWithPooling = self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "\n",
    "        image_embeds = vision_outputs.pooler_output\n",
    "\n",
    "        text_embeds = text_outputs.pooler_output\n",
    "\n",
    "        return CLIPOutput(\n",
    "            text_embeds=text_embeds,\n",
    "            image_embeds=image_embeds,\n",
    "            text_model_output=text_outputs,\n",
    "            vision_model_output=vision_outputs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ede5f2",
   "metadata": {},
   "source": [
    "### 가중치 불러오기(hugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61aa557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 수집된 이미지-텍스트 쌍: 14000\n",
      "CLIPMLP(\n",
      "  (activation_fn): QuickGELUActivation()\n",
      "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()  # Suppress warnings from transformers\n",
    "\n",
    "batch_size = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root_dir = r\"C:\\visual code\\MRI\\dataset\\MRI_train\" # 실제 경로로 교체 필요\n",
    "imagetext_dataset = collect_image_text_pairs(root_dir)\n",
    "\n",
    "dataset = CLIPDataset(imagetext_dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
    "# print(model)\n",
    "print(model.text_model.encoder.layers[0].mlp)\n",
    "\n",
    "weights=torch.load('C:/visual code/MRI/RadCLIP.pth', map_location=device)\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e6de4",
   "metadata": {},
   "source": [
    "### 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ce92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[-0.0345, -0.0010],\n",
      "        [-0.0039,  0.0290],\n",
      "        [-0.0234,  0.0102],\n",
      "        [ 0.0040,  0.0414]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[-0.0179,  0.0129],\n",
      "        [-0.0118,  0.0149],\n",
      "        [-0.0198,  0.0054],\n",
      "        [ 0.0036,  0.0320]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0252, 0.0518],\n",
      "        [0.0244, 0.0471],\n",
      "        [0.0405, 0.0649],\n",
      "        [0.0375, 0.0540]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0291, 0.0507],\n",
      "        [0.0369, 0.0556],\n",
      "        [0.0256, 0.0595],\n",
      "        [0.0365, 0.0655]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0440, 0.0461],\n",
      "        [0.0357, 0.0493],\n",
      "        [0.0302, 0.0425],\n",
      "        [0.0289, 0.0467]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0413, 0.0462],\n",
      "        [0.0178, 0.0303],\n",
      "        [0.0192, 0.0324],\n",
      "        [0.0412, 0.0453]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0377, 0.0497],\n",
      "        [0.0427, 0.0502],\n",
      "        [0.0389, 0.0403],\n",
      "        [0.0317, 0.0403]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0381, 0.0453],\n",
      "        [0.0371, 0.0468],\n",
      "        [0.0415, 0.0445],\n",
      "        [0.0375, 0.0461]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0464, 0.0573],\n",
      "        [0.0495, 0.0702],\n",
      "        [0.0594, 0.0792],\n",
      "        [0.0482, 0.0713]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0476, 0.0596],\n",
      "        [0.0686, 0.0746],\n",
      "        [0.0652, 0.0716],\n",
      "        [0.0653, 0.0695]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0617, 0.0689],\n",
      "        [0.0592, 0.0670],\n",
      "        [0.0523, 0.0620],\n",
      "        [0.0465, 0.0546]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0466, 0.0497],\n",
      "        [0.0407, 0.0460],\n",
      "        [0.0506, 0.0509],\n",
      "        [0.0557, 0.0571]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 0\n",
      "Logits: tensor([[0.0564, 0.0567],\n",
      "        [0.0529, 0.0519],\n",
      "        [0.0405, 0.0396],\n",
      "        [0.0401, 0.0363]]), Preds: tensor([1, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 3\n",
      "Logits: tensor([[0.0399, 0.0334],\n",
      "        [0.0361, 0.0296],\n",
      "        [0.0288, 0.0263],\n",
      "        [0.0190, 0.0191]]), Preds: tensor([0, 0, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 6\n",
      "Logits: tensor([[0.0213, 0.0191],\n",
      "        [0.0209, 0.0165],\n",
      "        [0.0184, 0.0170],\n",
      "        [0.0177, 0.0147]]), Preds: tensor([0, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 10\n",
      "Logits: tensor([[-0.0044, -0.0021],\n",
      "        [-0.0132, -0.0089],\n",
      "        [-0.0289, -0.0185],\n",
      "        [-0.0245, -0.0124]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 10\n",
      "Logits: tensor([[-0.0121, -0.0093],\n",
      "        [ 0.0004,  0.0048],\n",
      "        [ 0.0235,  0.0280],\n",
      "        [ 0.0340,  0.0442]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 10\n",
      "Logits: tensor([[ 0.0469,  0.0534],\n",
      "        [-0.0151,  0.0210],\n",
      "        [-0.0107,  0.0183],\n",
      "        [-0.0137,  0.0285]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 10\n",
      "Logits: tensor([[-0.0141,  0.0213],\n",
      "        [-0.0098,  0.0065],\n",
      "        [-0.0190,  0.0050],\n",
      "        [-0.0442, -0.0245]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 10\n",
      "Logits: tensor([[-0.0116, -0.0032],\n",
      "        [ 0.0016,  0.0184],\n",
      "        [ 0.0004,  0.0130],\n",
      "        [ 0.0053,  0.0172]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 10\n",
      "Logits: tensor([[0.0065, 0.0191],\n",
      "        [0.0282, 0.0421],\n",
      "        [0.0102, 0.0384],\n",
      "        [0.0212, 0.0514]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 10\n",
      "Logits: tensor([[ 0.0299,  0.0624],\n",
      "        [-0.0151,  0.0117],\n",
      "        [ 0.0073,  0.0244],\n",
      "        [ 0.0349,  0.0333]]), Preds: tensor([1, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0406, 0.0444],\n",
      "        [0.0609, 0.0622],\n",
      "        [0.0519, 0.0572],\n",
      "        [0.0531, 0.0589]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0543, 0.0605],\n",
      "        [0.0515, 0.0666],\n",
      "        [0.0525, 0.0660],\n",
      "        [0.0402, 0.0602]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0404, 0.0553],\n",
      "        [0.0550, 0.0695],\n",
      "        [0.0549, 0.0704],\n",
      "        [0.0526, 0.0601]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0452, 0.0568],\n",
      "        [0.0512, 0.0609],\n",
      "        [0.0504, 0.0587],\n",
      "        [0.0504, 0.0565]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0367, 0.0457],\n",
      "        [0.0469, 0.0585],\n",
      "        [0.0352, 0.0578],\n",
      "        [0.0263, 0.0537]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0430, 0.0687],\n",
      "        [0.0506, 0.0631],\n",
      "        [0.0599, 0.0769],\n",
      "        [0.0489, 0.0704]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0483, 0.0670],\n",
      "        [0.0551, 0.0672],\n",
      "        [0.0524, 0.0654],\n",
      "        [0.0477, 0.0609]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0472, 0.0555],\n",
      "        [0.0502, 0.0604],\n",
      "        [0.0519, 0.0640],\n",
      "        [0.0530, 0.0617]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0477, 0.0546],\n",
      "        [0.0450, 0.0480],\n",
      "        [0.0500, 0.0502],\n",
      "        [0.0433, 0.0518]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0311, 0.0393],\n",
      "        [0.0354, 0.0429],\n",
      "        [0.0295, 0.0378],\n",
      "        [0.0441, 0.0493]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0419, 0.0436],\n",
      "        [0.0297, 0.0365],\n",
      "        [0.0217, 0.0280],\n",
      "        [0.0053, 0.0139]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[-0.0097, -0.0011],\n",
      "        [ 0.0009,  0.0078],\n",
      "        [-0.0171, -0.0024],\n",
      "        [-0.0159,  0.0117]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[ 0.0082,  0.0388],\n",
      "        [-0.0061,  0.0265],\n",
      "        [ 0.0151,  0.0366],\n",
      "        [ 0.0355,  0.0622]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[ 0.0220,  0.0273],\n",
      "        [-0.0100,  0.0101],\n",
      "        [-0.0036,  0.0124],\n",
      "        [ 0.0242,  0.0369]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[ 0.0268,  0.0435],\n",
      "        [ 0.0337,  0.0529],\n",
      "        [-0.0158,  0.0105],\n",
      "        [ 0.0016,  0.0168]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0083, 0.0133],\n",
      "        [0.0257, 0.0383],\n",
      "        [0.0292, 0.0495],\n",
      "        [0.0427, 0.0673]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 11\n",
      "Logits: tensor([[0.0418, 0.0481],\n",
      "        [0.0321, 0.0318],\n",
      "        [0.0142, 0.0122],\n",
      "        [0.0189, 0.0173]]), Preds: tensor([1, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 14\n",
      "Logits: tensor([[0.0427, 0.0458],\n",
      "        [0.0449, 0.0482],\n",
      "        [0.0557, 0.0556],\n",
      "        [0.0446, 0.0539]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 15\n",
      "Logits: tensor([[0.0400, 0.0566],\n",
      "        [0.0503, 0.0569],\n",
      "        [0.0425, 0.0536],\n",
      "        [0.0368, 0.0470]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 15\n",
      "Logits: tensor([[0.0387, 0.0471],\n",
      "        [0.0380, 0.0499],\n",
      "        [0.0548, 0.0702],\n",
      "        [0.0483, 0.0627]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 15\n",
      "Logits: tensor([[0.0455, 0.0562],\n",
      "        [0.0401, 0.0496],\n",
      "        [0.0464, 0.0602],\n",
      "        [0.0474, 0.0615]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 15\n",
      "Logits: tensor([[0.0505, 0.0655],\n",
      "        [0.0489, 0.0655],\n",
      "        [0.0411, 0.0601],\n",
      "        [0.0430, 0.0613]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 15\n",
      "Logits: tensor([[0.0593, 0.0686],\n",
      "        [0.0563, 0.0633],\n",
      "        [0.0572, 0.0629],\n",
      "        [0.0611, 0.0689]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 15\n",
      "Logits: tensor([[0.0500, 0.0585],\n",
      "        [0.0523, 0.0616],\n",
      "        [0.0451, 0.0544],\n",
      "        [0.0325, 0.0435]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 15\n",
      "Logits: tensor([[0.0296, 0.0367],\n",
      "        [0.0523, 0.0520],\n",
      "        [0.0475, 0.0513],\n",
      "        [0.0429, 0.0449]]), Preds: tensor([1, 0, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 16\n",
      "Logits: tensor([[0.0466, 0.0501],\n",
      "        [0.0537, 0.0539],\n",
      "        [0.0509, 0.0451],\n",
      "        [0.0378, 0.0322]]), Preds: tensor([1, 1, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 18\n",
      "Logits: tensor([[0.0442, 0.0399],\n",
      "        [0.0374, 0.0341],\n",
      "        [0.0351, 0.0335],\n",
      "        [0.0372, 0.0329]]), Preds: tensor([0, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 22\n",
      "Logits: tensor([[0.0427, 0.0355],\n",
      "        [0.0423, 0.0374],\n",
      "        [0.0352, 0.0355],\n",
      "        [0.0344, 0.0362]]), Preds: tensor([0, 0, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 24\n",
      "Logits: tensor([[0.0288, 0.0277],\n",
      "        [0.0209, 0.0249],\n",
      "        [0.0078, 0.0137],\n",
      "        [0.0214, 0.0237]]), Preds: tensor([0, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 25\n",
      "Logits: tensor([[0.0192, 0.0210],\n",
      "        [0.0174, 0.0201],\n",
      "        [0.0173, 0.0263],\n",
      "        [0.0284, 0.0483]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 25\n",
      "Logits: tensor([[ 0.0232,  0.0503],\n",
      "        [ 0.0116,  0.0366],\n",
      "        [-0.0144,  0.0216],\n",
      "        [ 0.0100,  0.0341]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 25\n",
      "Logits: tensor([[-0.0176,  0.0116],\n",
      "        [ 0.0169,  0.0397],\n",
      "        [ 0.0327,  0.0545],\n",
      "        [ 0.0296,  0.0497]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 25\n",
      "Logits: tensor([[0.0246, 0.0562],\n",
      "        [0.0169, 0.0491],\n",
      "        [0.0201, 0.0549],\n",
      "        [0.0358, 0.0646]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 25\n",
      "Logits: tensor([[0.0337, 0.0378],\n",
      "        [0.0220, 0.0311],\n",
      "        [0.0137, 0.0216],\n",
      "        [0.0453, 0.0553]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 25\n",
      "Logits: tensor([[0.0462, 0.0536],\n",
      "        [0.0523, 0.0572],\n",
      "        [0.0708, 0.0695],\n",
      "        [0.0589, 0.0669]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0353, 0.0451],\n",
      "        [0.0397, 0.0542],\n",
      "        [0.0415, 0.0520],\n",
      "        [0.0414, 0.0502]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0401, 0.0470],\n",
      "        [0.0441, 0.0565],\n",
      "        [0.0513, 0.0610],\n",
      "        [0.0365, 0.0440]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0345, 0.0425],\n",
      "        [0.0414, 0.0494],\n",
      "        [0.0394, 0.0490],\n",
      "        [0.0477, 0.0566]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0503, 0.0702],\n",
      "        [0.0433, 0.0617],\n",
      "        [0.0395, 0.0658],\n",
      "        [0.0491, 0.0747]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0527, 0.0669],\n",
      "        [0.0409, 0.0509],\n",
      "        [0.0379, 0.0491],\n",
      "        [0.0468, 0.0560]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0411, 0.0508],\n",
      "        [0.0414, 0.0490],\n",
      "        [0.0403, 0.0536],\n",
      "        [0.0344, 0.0444]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0316, 0.0399],\n",
      "        [0.0425, 0.0522],\n",
      "        [0.0464, 0.0506],\n",
      "        [0.0374, 0.0462]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0376, 0.0465],\n",
      "        [0.0309, 0.0415],\n",
      "        [0.0438, 0.0526],\n",
      "        [0.0414, 0.0448]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 26\n",
      "Logits: tensor([[0.0461, 0.0439],\n",
      "        [0.0444, 0.0468],\n",
      "        [0.0300, 0.0313],\n",
      "        [0.0311, 0.0354]]), Preds: tensor([0, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 27\n",
      "Logits: tensor([[0.0375, 0.0418],\n",
      "        [0.0472, 0.0468],\n",
      "        [0.0250, 0.0270],\n",
      "        [0.0118, 0.0180]]), Preds: tensor([1, 0, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 28\n",
      "Logits: tensor([[-0.0027,  0.0060],\n",
      "        [-0.0096,  0.0092],\n",
      "        [ 0.0011,  0.0176],\n",
      "        [-0.0031,  0.0113]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 28\n",
      "Logits: tensor([[-0.0048,  0.0186],\n",
      "        [-0.0126,  0.0019],\n",
      "        [-0.0248, -0.0060],\n",
      "        [-0.0300, -0.0141]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 28\n",
      "Logits: tensor([[-0.0121, -0.0013],\n",
      "        [ 0.0315,  0.0371],\n",
      "        [ 0.0507,  0.0745],\n",
      "        [-0.0276, -0.0088]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 28\n",
      "Logits: tensor([[-0.0228,  0.0142],\n",
      "        [-0.0182,  0.0139],\n",
      "        [ 0.0025,  0.0233],\n",
      "        [ 0.0019,  0.0148]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 28\n",
      "Logits: tensor([[0.0303, 0.0366],\n",
      "        [0.0304, 0.0380],\n",
      "        [0.0224, 0.0370],\n",
      "        [0.0501, 0.0646]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 28\n",
      "Logits: tensor([[0.0470, 0.0662],\n",
      "        [0.0376, 0.0578],\n",
      "        [0.0504, 0.0641],\n",
      "        [0.0410, 0.0537]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 28\n",
      "Logits: tensor([[0.0259, 0.0336],\n",
      "        [0.0188, 0.0184],\n",
      "        [0.0309, 0.0354],\n",
      "        [0.0365, 0.0481]]), Preds: tensor([1, 0, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 29\n",
      "Logits: tensor([[0.0635, 0.0677],\n",
      "        [0.0568, 0.0619],\n",
      "        [0.0547, 0.0549],\n",
      "        [0.0443, 0.0502]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 29\n",
      "Logits: tensor([[0.0395, 0.0473],\n",
      "        [0.0315, 0.0391],\n",
      "        [0.0359, 0.0525],\n",
      "        [0.0422, 0.0493]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 29\n",
      "Logits: tensor([[0.0324, 0.0393],\n",
      "        [0.0365, 0.0433],\n",
      "        [0.0353, 0.0464],\n",
      "        [0.0346, 0.0446]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 29\n",
      "Logits: tensor([[0.0434, 0.0485],\n",
      "        [0.0489, 0.0553],\n",
      "        [0.0420, 0.0504],\n",
      "        [0.0427, 0.0479]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 29\n",
      "Logits: tensor([[0.0501, 0.0474],\n",
      "        [0.0424, 0.0491],\n",
      "        [0.0390, 0.0406],\n",
      "        [0.0394, 0.0446]]), Preds: tensor([0, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 30\n",
      "Logits: tensor([[0.0434, 0.0494],\n",
      "        [0.0452, 0.0510],\n",
      "        [0.0448, 0.0511],\n",
      "        [0.0327, 0.0430]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 30\n",
      "Logits: tensor([[0.0388, 0.0464],\n",
      "        [0.0394, 0.0489],\n",
      "        [0.0356, 0.0419],\n",
      "        [0.0436, 0.0463]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 30\n",
      "Logits: tensor([[0.0453, 0.0491],\n",
      "        [0.0437, 0.0463],\n",
      "        [0.0461, 0.0492],\n",
      "        [0.0457, 0.0500]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 30\n",
      "Logits: tensor([[0.0524, 0.0547],\n",
      "        [0.0397, 0.0389],\n",
      "        [0.0383, 0.0350],\n",
      "        [0.0284, 0.0250]]), Preds: tensor([1, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 33\n",
      "Logits: tensor([[0.0320, 0.0228],\n",
      "        [0.0364, 0.0301],\n",
      "        [0.0364, 0.0320],\n",
      "        [0.0419, 0.0401]]), Preds: tensor([0, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 37\n",
      "Logits: tensor([[0.0321, 0.0319],\n",
      "        [0.0314, 0.0253],\n",
      "        [0.0277, 0.0255],\n",
      "        [0.0313, 0.0250]]), Preds: tensor([0, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 41\n",
      "Logits: tensor([[ 0.0059,  0.0113],\n",
      "        [-0.0142, -0.0015],\n",
      "        [-0.0005,  0.0129],\n",
      "        [-0.0151, -0.0002]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 41\n",
      "Logits: tensor([[0.0092, 0.0220],\n",
      "        [0.0070, 0.0084],\n",
      "        [0.0138, 0.0092],\n",
      "        [0.0306, 0.0439]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 42\n",
      "Logits: tensor([[ 0.0635,  0.0719],\n",
      "        [ 0.0530,  0.0837],\n",
      "        [-0.0002,  0.0377],\n",
      "        [-0.0011,  0.0263]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 42\n",
      "Logits: tensor([[-0.0337,  0.0066],\n",
      "        [-0.0075,  0.0238],\n",
      "        [ 0.0041,  0.0308],\n",
      "        [ 0.0465,  0.0686]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 42\n",
      "Logits: tensor([[0.0276, 0.0498],\n",
      "        [0.0379, 0.0533],\n",
      "        [0.0547, 0.0774],\n",
      "        [0.0277, 0.0578]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 42\n",
      "Logits: tensor([[0.0356, 0.0609],\n",
      "        [0.0409, 0.0453],\n",
      "        [0.0290, 0.0429],\n",
      "        [0.0150, 0.0435]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 42\n",
      "Logits: tensor([[0.0126, 0.0358],\n",
      "        [0.0155, 0.0280],\n",
      "        [0.0545, 0.0648],\n",
      "        [0.0719, 0.0781]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 42\n",
      "Logits: tensor([[0.0754, 0.0733],\n",
      "        [0.0774, 0.0810],\n",
      "        [0.0692, 0.0782],\n",
      "        [0.0572, 0.0732]]), Preds: tensor([0, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0530, 0.0608],\n",
      "        [0.0376, 0.0444],\n",
      "        [0.0406, 0.0491],\n",
      "        [0.0406, 0.0561]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0446, 0.0531],\n",
      "        [0.0514, 0.0530],\n",
      "        [0.0479, 0.0542],\n",
      "        [0.0332, 0.0455]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0456, 0.0537],\n",
      "        [0.0310, 0.0371],\n",
      "        [0.0344, 0.0425],\n",
      "        [0.0471, 0.0542]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0420, 0.0544],\n",
      "        [0.0390, 0.0538],\n",
      "        [0.0422, 0.0527],\n",
      "        [0.0457, 0.0524]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0380, 0.0478],\n",
      "        [0.0408, 0.0513],\n",
      "        [0.0356, 0.0460],\n",
      "        [0.0366, 0.0479]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0471, 0.0543],\n",
      "        [0.0439, 0.0536],\n",
      "        [0.0378, 0.0454],\n",
      "        [0.0387, 0.0474]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0406, 0.0486],\n",
      "        [0.0282, 0.0377],\n",
      "        [0.0257, 0.0393],\n",
      "        [0.0348, 0.0472]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0469, 0.0524],\n",
      "        [0.0442, 0.0490],\n",
      "        [0.0459, 0.0481],\n",
      "        [0.0398, 0.0406]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 43\n",
      "Logits: tensor([[0.0378, 0.0395],\n",
      "        [0.0271, 0.0300],\n",
      "        [0.0073, 0.0094],\n",
      "        [0.0104, 0.0102]]), Preds: tensor([1, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0071, 0.0114],\n",
      "        [0.0220, 0.0255],\n",
      "        [0.0217, 0.0350],\n",
      "        [0.0158, 0.0331]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[ 0.0007,  0.0150],\n",
      "        [-0.0195, -0.0064],\n",
      "        [-0.0246, -0.0207],\n",
      "        [-0.0031,  0.0008]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[-0.0179, -0.0139],\n",
      "        [ 0.0122,  0.0170],\n",
      "        [ 0.0501,  0.0678],\n",
      "        [ 0.0458,  0.0663]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[ 0.0070,  0.0310],\n",
      "        [-0.0023,  0.0238],\n",
      "        [-0.0324, -0.0023],\n",
      "        [-0.0372, -0.0097]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0020, 0.0263],\n",
      "        [0.0160, 0.0391],\n",
      "        [0.0253, 0.0492],\n",
      "        [0.0408, 0.0598]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0418, 0.0564],\n",
      "        [0.0196, 0.0399],\n",
      "        [0.0175, 0.0289],\n",
      "        [0.0193, 0.0333]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0315, 0.0353],\n",
      "        [0.0301, 0.0355],\n",
      "        [0.0097, 0.0299],\n",
      "        [0.0265, 0.0381]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0304, 0.0375],\n",
      "        [0.0261, 0.0324],\n",
      "        [0.0168, 0.0241],\n",
      "        [0.0209, 0.0291]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0254, 0.0301],\n",
      "        [0.0393, 0.0470],\n",
      "        [0.0345, 0.0458],\n",
      "        [0.0351, 0.0454]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0322, 0.0485],\n",
      "        [0.0393, 0.0467],\n",
      "        [0.0329, 0.0415],\n",
      "        [0.0430, 0.0507]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0423, 0.0486],\n",
      "        [0.0429, 0.0470],\n",
      "        [0.0416, 0.0515],\n",
      "        [0.0416, 0.0546]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0438, 0.0579],\n",
      "        [0.0424, 0.0636],\n",
      "        [0.0429, 0.0620],\n",
      "        [0.0519, 0.0582]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0491, 0.0566],\n",
      "        [0.0416, 0.0494],\n",
      "        [0.0346, 0.0441],\n",
      "        [0.0205, 0.0305]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0255, 0.0319],\n",
      "        [0.0233, 0.0282],\n",
      "        [0.0215, 0.0335],\n",
      "        [0.0104, 0.0259]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0221, 0.0328],\n",
      "        [0.0274, 0.0330],\n",
      "        [0.0317, 0.0373],\n",
      "        [0.0256, 0.0330]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0359, 0.0424],\n",
      "        [0.0364, 0.0402],\n",
      "        [0.0414, 0.0430],\n",
      "        [0.0432, 0.0433]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 44\n",
      "Logits: tensor([[0.0414, 0.0388],\n",
      "        [0.0324, 0.0326],\n",
      "        [0.0295, 0.0322],\n",
      "        [0.0325, 0.0334]]), Preds: tensor([0, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 45\n",
      "Logits: tensor([[0.0300, 0.0274],\n",
      "        [0.0296, 0.0276],\n",
      "        [0.0250, 0.0236],\n",
      "        [0.0166, 0.0218]]), Preds: tensor([0, 0, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0102, 0.0215],\n",
      "        [0.0165, 0.0318],\n",
      "        [0.0172, 0.0376],\n",
      "        [0.0182, 0.0372]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[ 0.0101,  0.0212],\n",
      "        [-0.0059,  0.0062],\n",
      "        [-0.0291, -0.0201],\n",
      "        [ 0.0217,  0.0479]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[ 0.0529,  0.0626],\n",
      "        [ 0.0094,  0.0419],\n",
      "        [-0.0174,  0.0164],\n",
      "        [-0.0228,  0.0178]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[ 0.0019,  0.0364],\n",
      "        [-0.0160, -0.0016],\n",
      "        [-0.0143,  0.0061],\n",
      "        [ 0.0148,  0.0370]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[-0.0001,  0.0244],\n",
      "        [ 0.0206,  0.0450],\n",
      "        [ 0.0320,  0.0651],\n",
      "        [ 0.0475,  0.0673]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0613, 0.0773],\n",
      "        [0.0491, 0.0644],\n",
      "        [0.0602, 0.0913],\n",
      "        [0.0379, 0.0708]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[ 0.0172,  0.0334],\n",
      "        [-0.0107,  0.0121],\n",
      "        [ 0.0074,  0.0226],\n",
      "        [ 0.0183,  0.0267]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0126, 0.0304],\n",
      "        [0.0226, 0.0385],\n",
      "        [0.0388, 0.0556],\n",
      "        [0.0358, 0.0484]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0282, 0.0444],\n",
      "        [0.0422, 0.0539],\n",
      "        [0.0265, 0.0381],\n",
      "        [0.0305, 0.0364]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0366, 0.0431],\n",
      "        [0.0428, 0.0504],\n",
      "        [0.0416, 0.0540],\n",
      "        [0.0357, 0.0481]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0440, 0.0556],\n",
      "        [0.0339, 0.0458],\n",
      "        [0.0429, 0.0571],\n",
      "        [0.0410, 0.0602]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0428, 0.0579],\n",
      "        [0.0472, 0.0549],\n",
      "        [0.0475, 0.0553],\n",
      "        [0.0522, 0.0648]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0414, 0.0554],\n",
      "        [0.0527, 0.0601],\n",
      "        [0.0544, 0.0620],\n",
      "        [0.0476, 0.0526]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0418, 0.0479],\n",
      "        [0.0406, 0.0462],\n",
      "        [0.0376, 0.0467],\n",
      "        [0.0317, 0.0407]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 48\n",
      "Logits: tensor([[0.0382, 0.0441],\n",
      "        [0.0374, 0.0419],\n",
      "        [0.0457, 0.0461],\n",
      "        [0.0386, 0.0371]]), Preds: tensor([1, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 49\n",
      "Logits: tensor([[0.0425, 0.0400],\n",
      "        [0.0429, 0.0366],\n",
      "        [0.0385, 0.0307],\n",
      "        [0.0301, 0.0249]]), Preds: tensor([0, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 53\n",
      "Logits: tensor([[0.0259, 0.0189],\n",
      "        [0.0239, 0.0167],\n",
      "        [0.0176, 0.0115],\n",
      "        [0.0072, 0.0102]]), Preds: tensor([0, 0, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 56\n",
      "Logits: tensor([[0.0037, 0.0127],\n",
      "        [0.0149, 0.0160],\n",
      "        [0.0233, 0.0219],\n",
      "        [0.0203, 0.0230]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 57\n",
      "Logits: tensor([[ 0.0253,  0.0345],\n",
      "        [-0.0119, -0.0073],\n",
      "        [-0.0432, -0.0326],\n",
      "        [-0.0362, -0.0365]]), Preds: tensor([1, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 58\n",
      "Logits: tensor([[ 0.0068,  0.0112],\n",
      "        [-0.0096,  0.0019],\n",
      "        [ 0.0165,  0.0229],\n",
      "        [ 0.0570,  0.0599]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 58\n",
      "Logits: tensor([[-0.0069,  0.0333],\n",
      "        [ 0.0176,  0.0588],\n",
      "        [-0.0072,  0.0304],\n",
      "        [-0.0006,  0.0324]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 58\n",
      "Logits: tensor([[-0.0095,  0.0172],\n",
      "        [-0.0146,  0.0119],\n",
      "        [ 0.0167,  0.0322],\n",
      "        [ 0.0211,  0.0410]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 58\n",
      "Logits: tensor([[0.0115, 0.0355],\n",
      "        [0.0431, 0.0573],\n",
      "        [0.0301, 0.0505],\n",
      "        [0.0276, 0.0606]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 58\n",
      "Logits: tensor([[0.0511, 0.0841],\n",
      "        [0.0423, 0.0721],\n",
      "        [0.0234, 0.0422],\n",
      "        [0.0474, 0.0471]]), Preds: tensor([1, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0134, 0.0285],\n",
      "        [0.0144, 0.0296],\n",
      "        [0.0251, 0.0428],\n",
      "        [0.0182, 0.0360]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0298, 0.0384],\n",
      "        [0.0278, 0.0286],\n",
      "        [0.0229, 0.0241],\n",
      "        [0.0248, 0.0252]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0136, 0.0291],\n",
      "        [0.0198, 0.0287],\n",
      "        [0.0176, 0.0238],\n",
      "        [0.0270, 0.0296]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0355, 0.0430],\n",
      "        [0.0405, 0.0523],\n",
      "        [0.0463, 0.0603],\n",
      "        [0.0461, 0.0576]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0542, 0.0687],\n",
      "        [0.0543, 0.0728],\n",
      "        [0.0473, 0.0694],\n",
      "        [0.0442, 0.0603]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0493, 0.0668],\n",
      "        [0.0602, 0.0638],\n",
      "        [0.0600, 0.0645],\n",
      "        [0.0536, 0.0591]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0535, 0.0616],\n",
      "        [0.0528, 0.0634],\n",
      "        [0.0484, 0.0605],\n",
      "        [0.0341, 0.0452]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0359, 0.0434],\n",
      "        [0.0318, 0.0388],\n",
      "        [0.0354, 0.0425],\n",
      "        [0.0381, 0.0466]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 59\n",
      "Logits: tensor([[0.0502, 0.0545],\n",
      "        [0.0614, 0.0598],\n",
      "        [0.0565, 0.0586],\n",
      "        [0.0427, 0.0436]]), Preds: tensor([1, 0, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 60\n",
      "Logits: tensor([[0.0386, 0.0374],\n",
      "        [0.0413, 0.0442],\n",
      "        [0.0284, 0.0286],\n",
      "        [0.0331, 0.0320]]), Preds: tensor([0, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 62\n",
      "Logits: tensor([[0.0375, 0.0373],\n",
      "        [0.0352, 0.0358],\n",
      "        [0.0349, 0.0431],\n",
      "        [0.0217, 0.0339]]), Preds: tensor([0, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[-0.0113,  0.0119],\n",
      "        [-0.0193,  0.0022],\n",
      "        [-0.0176, -0.0027],\n",
      "        [-0.0144, -0.0073]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[-0.0187, -0.0057],\n",
      "        [-0.0137, -0.0026],\n",
      "        [ 0.0154,  0.0215],\n",
      "        [ 0.0205,  0.0364]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[ 0.0319,  0.0452],\n",
      "        [-0.0161,  0.0062],\n",
      "        [-0.0262,  0.0035],\n",
      "        [-0.0013,  0.0378]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[-0.0180,  0.0116],\n",
      "        [-0.0138,  0.0037],\n",
      "        [ 0.0016,  0.0132],\n",
      "        [-0.0004,  0.0134]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[0.0066, 0.0275],\n",
      "        [0.0033, 0.0207],\n",
      "        [0.0217, 0.0324],\n",
      "        [0.0331, 0.0583]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[0.0422, 0.0661],\n",
      "        [0.0430, 0.0638],\n",
      "        [0.0299, 0.0495],\n",
      "        [0.0333, 0.0405]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[0.0344, 0.0393],\n",
      "        [0.0363, 0.0401],\n",
      "        [0.0271, 0.0466],\n",
      "        [0.0210, 0.0403]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 63\n",
      "Logits: tensor([[0.0394, 0.0344],\n",
      "        [0.0821, 0.0805],\n",
      "        [0.0596, 0.0651],\n",
      "        [0.0591, 0.0669]]), Preds: tensor([0, 0, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0520, 0.0551],\n",
      "        [0.0478, 0.0567],\n",
      "        [0.0411, 0.0515],\n",
      "        [0.0358, 0.0469]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0325, 0.0430],\n",
      "        [0.0401, 0.0511],\n",
      "        [0.0528, 0.0610],\n",
      "        [0.0468, 0.0553]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0473, 0.0670],\n",
      "        [0.0525, 0.0692],\n",
      "        [0.0590, 0.0762],\n",
      "        [0.0463, 0.0708]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0466, 0.0667],\n",
      "        [0.0548, 0.0686],\n",
      "        [0.0475, 0.0613],\n",
      "        [0.0407, 0.0510]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0422, 0.0578],\n",
      "        [0.0491, 0.0608],\n",
      "        [0.0529, 0.0616],\n",
      "        [0.0540, 0.0638]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0487, 0.0574],\n",
      "        [0.0425, 0.0504],\n",
      "        [0.0516, 0.0555],\n",
      "        [0.0525, 0.0601]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0573, 0.0616],\n",
      "        [0.0532, 0.0567],\n",
      "        [0.0584, 0.0620],\n",
      "        [0.0573, 0.0628]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 65\n",
      "Logits: tensor([[0.0514, 0.0562],\n",
      "        [0.0469, 0.0481],\n",
      "        [0.0412, 0.0368],\n",
      "        [0.0380, 0.0312]]), Preds: tensor([1, 1, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 67\n",
      "Logits: tensor([[0.0344, 0.0274],\n",
      "        [0.0327, 0.0251],\n",
      "        [0.0338, 0.0260],\n",
      "        [0.0209, 0.0224]]), Preds: tensor([0, 0, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 70\n",
      "Logits: tensor([[0.0334, 0.0394],\n",
      "        [0.0404, 0.0470],\n",
      "        [0.0305, 0.0361],\n",
      "        [0.0332, 0.0287]]), Preds: tensor([1, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 71\n",
      "Logits: tensor([[ 0.0272,  0.0310],\n",
      "        [ 0.0181,  0.0310],\n",
      "        [ 0.0128,  0.0279],\n",
      "        [-0.0318, -0.0152]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 71\n",
      "Logits: tensor([[-0.0099,  0.0138],\n",
      "        [ 0.0341,  0.0445],\n",
      "        [-0.0339, -0.0064],\n",
      "        [-0.0394, -0.0067]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 71\n",
      "Logits: tensor([[-0.0118,  0.0195],\n",
      "        [-0.0146,  0.0245],\n",
      "        [-0.0127,  0.0154],\n",
      "        [-0.0211,  0.0186]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 71\n",
      "Logits: tensor([[-0.0066,  0.0238],\n",
      "        [ 0.0209,  0.0266],\n",
      "        [ 0.0298,  0.0467],\n",
      "        [ 0.0277,  0.0464]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 71\n",
      "Logits: tensor([[0.0208, 0.0442],\n",
      "        [0.0387, 0.0512],\n",
      "        [0.0256, 0.0431],\n",
      "        [0.0342, 0.0636]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 71\n",
      "Logits: tensor([[0.0381, 0.0699],\n",
      "        [0.0445, 0.0695],\n",
      "        [0.0426, 0.0517],\n",
      "        [0.0175, 0.0185]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 71\n",
      "Logits: tensor([[0.0156, 0.0146],\n",
      "        [0.0350, 0.0352],\n",
      "        [0.0347, 0.0394],\n",
      "        [0.0317, 0.0317]]), Preds: tensor([0, 1, 1, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0374, 0.0503],\n",
      "        [0.0408, 0.0505],\n",
      "        [0.0428, 0.0563],\n",
      "        [0.0307, 0.0447]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0200, 0.0416],\n",
      "        [0.0222, 0.0391],\n",
      "        [0.0178, 0.0350],\n",
      "        [0.0390, 0.0590]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0317, 0.0592],\n",
      "        [0.0433, 0.0690],\n",
      "        [0.0471, 0.0604],\n",
      "        [0.0466, 0.0597]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0475, 0.0694],\n",
      "        [0.0620, 0.0894],\n",
      "        [0.0640, 0.0787],\n",
      "        [0.0568, 0.0690]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0495, 0.0543],\n",
      "        [0.0554, 0.0629],\n",
      "        [0.0544, 0.0624],\n",
      "        [0.0346, 0.0424]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0382, 0.0463],\n",
      "        [0.0361, 0.0490],\n",
      "        [0.0349, 0.0454],\n",
      "        [0.0273, 0.0383]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0341, 0.0412],\n",
      "        [0.0389, 0.0421],\n",
      "        [0.0441, 0.0479],\n",
      "        [0.0520, 0.0547]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0450, 0.0478],\n",
      "        [0.0340, 0.0407],\n",
      "        [0.0360, 0.0376],\n",
      "        [0.0421, 0.0435]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 73\n",
      "Logits: tensor([[0.0441, 0.0430],\n",
      "        [0.0381, 0.0368],\n",
      "        [0.0387, 0.0345],\n",
      "        [0.0358, 0.0305]]), Preds: tensor([0, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 77\n",
      "Logits: tensor([[0.0254, 0.0227],\n",
      "        [0.0250, 0.0236],\n",
      "        [0.0307, 0.0327],\n",
      "        [0.0159, 0.0220]]), Preds: tensor([0, 0, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 79\n",
      "Logits: tensor([[ 0.0001,  0.0084],\n",
      "        [-0.0149,  0.0031],\n",
      "        [-0.0156, -0.0009],\n",
      "        [-0.0172, -0.0064]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 79\n",
      "Logits: tensor([[-0.0118,  0.0004],\n",
      "        [-0.0404, -0.0256],\n",
      "        [-0.0189, -0.0108],\n",
      "        [-0.0116, -0.0082]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 79\n",
      "Logits: tensor([[0.0182, 0.0247],\n",
      "        [0.0141, 0.0207],\n",
      "        [0.0053, 0.0265],\n",
      "        [0.0055, 0.0320]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 79\n",
      "Logits: tensor([[0.0219, 0.0274],\n",
      "        [0.0160, 0.0311],\n",
      "        [0.0307, 0.0418],\n",
      "        [0.0290, 0.0484]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 79\n",
      "Logits: tensor([[0.0455, 0.0836],\n",
      "        [0.0528, 0.1032],\n",
      "        [0.0374, 0.0894],\n",
      "        [0.0218, 0.0594]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 79\n",
      "Logits: tensor([[ 0.0151,  0.0393],\n",
      "        [ 0.0220,  0.0383],\n",
      "        [ 0.0002,  0.0113],\n",
      "        [-0.0025,  0.0135]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 79\n",
      "Logits: tensor([[-0.0111,  0.0077],\n",
      "        [ 0.0094,  0.0206],\n",
      "        [ 0.0488,  0.0481],\n",
      "        [ 0.0577,  0.0522]]), Preds: tensor([1, 1, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0323, 0.0324],\n",
      "        [0.0221, 0.0286],\n",
      "        [0.0463, 0.0559],\n",
      "        [0.0403, 0.0565]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0367, 0.0465],\n",
      "        [0.0417, 0.0509],\n",
      "        [0.0402, 0.0526],\n",
      "        [0.0407, 0.0500]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0454, 0.0559],\n",
      "        [0.0443, 0.0548],\n",
      "        [0.0440, 0.0550],\n",
      "        [0.0493, 0.0587]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0529, 0.0688],\n",
      "        [0.0450, 0.0566],\n",
      "        [0.0488, 0.0582],\n",
      "        [0.0440, 0.0542]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0584, 0.0631],\n",
      "        [0.0491, 0.0549],\n",
      "        [0.0462, 0.0539],\n",
      "        [0.0446, 0.0545]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0447, 0.0555],\n",
      "        [0.0462, 0.0536],\n",
      "        [0.0473, 0.0521],\n",
      "        [0.0494, 0.0565]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0555, 0.0633],\n",
      "        [0.0491, 0.0558],\n",
      "        [0.0442, 0.0482],\n",
      "        [0.0413, 0.0476]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0495, 0.0541],\n",
      "        [0.0486, 0.0528],\n",
      "        [0.0442, 0.0484],\n",
      "        [0.0472, 0.0497]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0446, 0.0476],\n",
      "        [0.0471, 0.0488],\n",
      "        [0.0411, 0.0434],\n",
      "        [0.0380, 0.0387]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0176, 0.0305],\n",
      "        [0.0108, 0.0191],\n",
      "        [0.0163, 0.0176],\n",
      "        [0.0215, 0.0237]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0196, 0.0335],\n",
      "        [0.0248, 0.0435],\n",
      "        [0.0200, 0.0312],\n",
      "        [0.0291, 0.0397]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[ 0.0369,  0.0514],\n",
      "        [ 0.0106,  0.0319],\n",
      "        [-0.0254, -0.0017],\n",
      "        [-0.0296, -0.0114]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[-1.2402e-02, -1.5106e-06],\n",
      "        [ 1.8911e-02,  3.5830e-02],\n",
      "        [ 1.2352e-02,  4.2594e-02],\n",
      "        [-2.5216e-02, -2.4075e-03]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[-0.0086,  0.0351],\n",
      "        [-0.0121,  0.0259],\n",
      "        [ 0.0018,  0.0393],\n",
      "        [ 0.0025,  0.0185]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[ 0.0037,  0.0118],\n",
      "        [-0.0069,  0.0133],\n",
      "        [ 0.0082,  0.0317],\n",
      "        [ 0.0201,  0.0403]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0395, 0.0581],\n",
      "        [0.0325, 0.0546],\n",
      "        [0.0342, 0.0451],\n",
      "        [0.0234, 0.0354]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0237, 0.0303],\n",
      "        [0.0236, 0.0301],\n",
      "        [0.0229, 0.0369],\n",
      "        [0.0257, 0.0398]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0216, 0.0322],\n",
      "        [0.0402, 0.0497],\n",
      "        [0.0360, 0.0449],\n",
      "        [0.0138, 0.0346]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0233, 0.0452],\n",
      "        [0.0535, 0.0668],\n",
      "        [0.0375, 0.0494],\n",
      "        [0.0443, 0.0481]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0441, 0.0569],\n",
      "        [0.0425, 0.0597],\n",
      "        [0.0311, 0.0542],\n",
      "        [0.0403, 0.0588]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0405, 0.0635],\n",
      "        [0.0430, 0.0622],\n",
      "        [0.0563, 0.0714],\n",
      "        [0.0616, 0.0719]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0578, 0.0699],\n",
      "        [0.0474, 0.0639],\n",
      "        [0.0359, 0.0620],\n",
      "        [0.0525, 0.0714]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0493, 0.0640],\n",
      "        [0.0447, 0.0553],\n",
      "        [0.0548, 0.0683],\n",
      "        [0.0442, 0.0576]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0513, 0.0630],\n",
      "        [0.0338, 0.0460],\n",
      "        [0.0455, 0.0531],\n",
      "        [0.0499, 0.0608]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0484, 0.0555],\n",
      "        [0.0513, 0.0597],\n",
      "        [0.0542, 0.0573],\n",
      "        [0.0550, 0.0598]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 81\n",
      "Logits: tensor([[0.0494, 0.0584],\n",
      "        [0.0478, 0.0524],\n",
      "        [0.0480, 0.0445],\n",
      "        [0.0458, 0.0449]]), Preds: tensor([1, 1, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 83\n",
      "Logits: tensor([[0.0419, 0.0361],\n",
      "        [0.0365, 0.0318],\n",
      "        [0.0374, 0.0330],\n",
      "        [0.0449, 0.0391]]), Preds: tensor([0, 0, 0, 0]), Labels: tensor([0, 0, 0, 0]), Correct: 87\n",
      "Logits: tensor([[0.0341, 0.0357],\n",
      "        [0.0328, 0.0336],\n",
      "        [0.0358, 0.0329],\n",
      "        [0.0307, 0.0330]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 88\n",
      "Logits: tensor([[0.0318, 0.0250],\n",
      "        [0.0455, 0.0442],\n",
      "        [0.0144, 0.0137],\n",
      "        [0.0190, 0.0241]]), Preds: tensor([0, 0, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 91\n",
      "Logits: tensor([[0.0143, 0.0229],\n",
      "        [0.0108, 0.0193],\n",
      "        [0.0494, 0.0489],\n",
      "        [0.0444, 0.0466]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 92\n",
      "Logits: tensor([[ 0.0206,  0.0279],\n",
      "        [ 0.0022,  0.0259],\n",
      "        [-0.0098,  0.0191],\n",
      "        [ 0.0049,  0.0286]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 92\n",
      "Logits: tensor([[-0.0340,  0.0022],\n",
      "        [-0.0220,  0.0069],\n",
      "        [-0.0287, -0.0095],\n",
      "        [ 0.0069,  0.0162]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 92\n",
      "Logits: tensor([[-0.0056,  0.0184],\n",
      "        [ 0.0243,  0.0408],\n",
      "        [ 0.0225,  0.0383],\n",
      "        [ 0.0100,  0.0252]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 92\n",
      "Logits: tensor([[0.0379, 0.0575],\n",
      "        [0.0525, 0.0780],\n",
      "        [0.0413, 0.0622],\n",
      "        [0.0267, 0.0402]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 92\n",
      "Logits: tensor([[0.0197, 0.0265],\n",
      "        [0.0292, 0.0373],\n",
      "        [0.0223, 0.0213],\n",
      "        [0.0036, 0.0096]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0138, 0.0297],\n",
      "        [0.0203, 0.0289],\n",
      "        [0.0268, 0.0353],\n",
      "        [0.0173, 0.0245]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0316, 0.0374],\n",
      "        [0.0414, 0.0488],\n",
      "        [0.0376, 0.0488],\n",
      "        [0.0367, 0.0496]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0410, 0.0534],\n",
      "        [0.0442, 0.0522],\n",
      "        [0.0482, 0.0553],\n",
      "        [0.0391, 0.0500]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0419, 0.0512],\n",
      "        [0.0413, 0.0528],\n",
      "        [0.0501, 0.0580],\n",
      "        [0.0489, 0.0592]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0494, 0.0599],\n",
      "        [0.0522, 0.0661],\n",
      "        [0.0460, 0.0693],\n",
      "        [0.0364, 0.0495]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0379, 0.0500],\n",
      "        [0.0343, 0.0458],\n",
      "        [0.0367, 0.0455],\n",
      "        [0.0386, 0.0484]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0427, 0.0519],\n",
      "        [0.0390, 0.0501],\n",
      "        [0.0199, 0.0339],\n",
      "        [0.0157, 0.0312]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0282, 0.0424],\n",
      "        [0.0409, 0.0486],\n",
      "        [0.0385, 0.0450],\n",
      "        [0.0341, 0.0411]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 93\n",
      "Logits: tensor([[0.0401, 0.0439],\n",
      "        [0.0468, 0.0488],\n",
      "        [0.0410, 0.0383],\n",
      "        [0.0362, 0.0365]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 94\n",
      "Logits: tensor([[0.0341, 0.0370],\n",
      "        [0.0380, 0.0403],\n",
      "        [0.0319, 0.0297],\n",
      "        [0.0175, 0.0204]]), Preds: tensor([1, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 95\n",
      "Logits: tensor([[0.0287, 0.0285],\n",
      "        [0.0320, 0.0325],\n",
      "        [0.0198, 0.0189],\n",
      "        [0.0129, 0.0146]]), Preds: tensor([0, 1, 0, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[ 0.0232,  0.0287],\n",
      "        [ 0.0127,  0.0131],\n",
      "        [ 0.0056,  0.0059],\n",
      "        [-0.0101, -0.0070]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[-0.0123, -0.0042],\n",
      "        [ 0.0057,  0.0222],\n",
      "        [ 0.0214,  0.0393],\n",
      "        [ 0.0223,  0.0447]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0148, 0.0294],\n",
      "        [0.0107, 0.0305],\n",
      "        [0.0025, 0.0237],\n",
      "        [0.0118, 0.0303]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0324, 0.0528],\n",
      "        [0.0149, 0.0402],\n",
      "        [0.0201, 0.0440],\n",
      "        [0.0351, 0.0600]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0204, 0.0378],\n",
      "        [0.0252, 0.0501],\n",
      "        [0.0337, 0.0456],\n",
      "        [0.0689, 0.0810]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0510, 0.0694],\n",
      "        [0.0595, 0.0612],\n",
      "        [0.0503, 0.0514],\n",
      "        [0.0506, 0.0542]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0624, 0.0707],\n",
      "        [0.0494, 0.0546],\n",
      "        [0.0408, 0.0458],\n",
      "        [0.0225, 0.0331]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0388, 0.0485],\n",
      "        [0.0242, 0.0354],\n",
      "        [0.0179, 0.0384],\n",
      "        [0.0291, 0.0431]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0269, 0.0363],\n",
      "        [0.0237, 0.0305],\n",
      "        [0.0364, 0.0415],\n",
      "        [0.0389, 0.0511]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0423, 0.0577],\n",
      "        [0.0494, 0.0553],\n",
      "        [0.0557, 0.0651],\n",
      "        [0.0440, 0.0625]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0375, 0.0544],\n",
      "        [0.0488, 0.0590],\n",
      "        [0.0520, 0.0580],\n",
      "        [0.0545, 0.0598]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0588, 0.0647],\n",
      "        [0.0538, 0.0594],\n",
      "        [0.0567, 0.0610],\n",
      "        [0.0475, 0.0561]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n",
      "Logits: tensor([[0.0357, 0.0458],\n",
      "        [0.0315, 0.0427],\n",
      "        [0.0412, 0.0531],\n",
      "        [0.0340, 0.0455]]), Preds: tensor([1, 1, 1, 1]), Labels: tensor([0, 0, 0, 0]), Correct: 97\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(model, dataloader, batch_size, device):\n",
    "    projection_dim = 768\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", use_fast=False)\n",
    "    visual_projection = nn.Linear(1024, projection_dim, bias=False).to(device)\n",
    "\n",
    "    # PD = 0, PDX = 1\n",
    "    text_prompts = {\n",
    "        \"PD\": [\n",
    "            \"Brain MRI with Parkinson's disease\",\n",
    "            \"T1-weighted axial brain MRI showing Parkinsonian features\",\n",
    "            \"MRI scan of the brain affected by Parkinson's disease\",\n",
    "            \"Neuroimaging of a patient diagnosed with Parkinson's\",\n",
    "            \"Axial brain MRI with signs of neurodegeneration\"\n",
    "        ],\n",
    "        \"PDX\": [\n",
    "            \"Brain MRI of a healthy subject\",\n",
    "            \"T1-weighted axial brain MRI without abnormalities\",\n",
    "            \"Normal brain scan with no pathological findings\",\n",
    "            \"Control subject brain MRI image\",\n",
    "            \"Axial brain MRI with typical anatomy and no disease\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # 1) 텍스트 특징 벡터 평균 계산\n",
    "    all_texts = text_prompts[\"PDX\"] + text_prompts[\"PD\"]\n",
    "    text_inputs = processor(text=all_texts, padding=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_embeds = model.get_text_features(**text_inputs)  # (10, 768)\n",
    "        healthy_text = text_embeds[:5].mean(dim=0, keepdim=True)     # (1, 768)\n",
    "        parkinson_text = text_embeds[5:].mean(dim=0, keepdim=True)   # (1, 768)\n",
    "        text_feats = torch.cat([parkinson_text, healthy_text], dim=0)  # (2, 768)\n",
    "\n",
    "    # 2) 평가 루프\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n",
    "            image_embeds = outputs.image_embeds  # (B, 1024)\n",
    "            image_proj = visual_projection(image_embeds)  # (B, 768)\n",
    "\n",
    "            # normalize\n",
    "            image_proj = image_proj / image_proj.norm(dim=-1, keepdim=True)\n",
    "            text_feats_norm = text_feats / text_feats.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            logits = image_proj @ text_feats_norm.T  # (B, 2)\n",
    "            preds = logits.argmax(dim=1)  # (B,)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            print(f\"Logits: {logits}, Preds: {preds}, Labels: {labels}, Correct: {correct}\")\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "acc = evaluate_accuracy(model, dataloader, batch_size, device)\n",
    "print(f\"Validation Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566e476",
   "metadata": {},
   "source": [
    "### 수정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "projection_dim = 768  # Assuming projection dimension is 768\n",
    "visual_projection = nn.Linear(1024, projection_dim, bias=False).to(device)\n",
    "text_projection = nn.Linear(768, projection_dim, bias=False).to(device)\n",
    "adapter = AttentionPoolingAdapter(embed_dim=1024, num_heads=8, num_slices=70).to(device)\n",
    "optimizer = torch.optim.AdamW(list(adapter.parameters())+list(visual_projection.parameters()), lr=1e-5)\n",
    "epochs = 10\n",
    "\n",
    "#freeze the text encoder of the model\n",
    "for param in model.text_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#freeze the vision encoder of the model\n",
    "for param in model.vision_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# freeze text projection\n",
    "for params in text_projection.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "# unfreeze visual projection\n",
    "for params in visual_projection.parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss=0\n",
    "    step=0\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        text_features = torch.empty(batch_size, 70, 768).to(device)  # Assuming 70 slices and 768 features\n",
    "        image_features = torch.empty(batch_size, 70, 1024).to(device)  # Assuming 70 slices and 1024 features\n",
    "\n",
    "        for idx in range(len(batch)):\n",
    "            input_ids = batch[idx]['input_ids'].to(device)\n",
    "            attention_mask = batch[idx]['attention_mask'].to(device)\n",
    "            pixel_values = batch[idx]['pixel_values'].to(device)\n",
    "            # print(f\"[Step {step}] input_ids: {input_ids.shape}, attention_mask: {attention_mask.shape}, pixel_values: {pixel_values.shape}\")\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n",
    "            text_features[:, idx, :] = outputs.text_embeds\n",
    "            image_features[:, idx, :] = outputs.image_embeds\n",
    "            #print(f\"[Step {step}] Text Features: {text_features.shape}, Image Features: {image_features.shape}\")\n",
    "\n",
    "        #print(image_features[0, :, 0], \"\\n\", image_features[1, :, 0], \"\\n\", image_features[2, :, 0], \"\\n\", image_features[3, :, 0])\n",
    "        #break\n",
    "\n",
    "        pooled_text_features = text_features[:, 0, :].squeeze(1)  # Assuming we want to pool the first slice\n",
    "        pooled_image_features = adapter(image_features) # Apply the SlicePoolingAdapter to image features\n",
    "        # print(f\"[Step {step}] Pooled Text Features: {pooled_text_features.shape}, Pooled Image Features: {pooled_image_features.shape}\")\n",
    "\n",
    "        # Project features to the same dimension\n",
    "        projected_texts  = text_projection(pooled_text_features)  # (4, projection_dim)\n",
    "        projected_images = visual_projection(pooled_image_features)  # (4, projection_dim)\n",
    "\n",
    "        # normalized features\n",
    "        projected_texts = projected_texts / _get_vector_norm(projected_texts)\n",
    "        projected_images = projected_images / _get_vector_norm(projected_images)\n",
    "\n",
    "        loss = contrastive_loss(projected_texts, projected_images)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimizer step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Step [{step+1}/{len(dataloader)}], Loss: {loss.item()}\")\n",
    "        step+=1\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(dataloader)}\")\n",
    "torch.save(model.state_dict(), \"clip_model_epoch_\"+str(epoch+1)+\".pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
